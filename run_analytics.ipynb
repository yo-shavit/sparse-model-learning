{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-30 19:06:50,873] Making new env: mnist-linear-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yonadav/Experiments/model-based/model-learning/data/mnist-linear-v0/default/train/run--30/model.ckpt-4993872\n",
      "model.ckpt-4993872\n",
      "data/fromphaedra/varying_x_scalar/linear_x0/\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import gym_mnist\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from model import EnvModel\n",
    "from modellearner import ModelLearner\n",
    "from utils.dataset import iterbatches\n",
    "import configs\n",
    "import numpy as np\n",
    "from utils.latent_visualizer import LatentVisualizer\n",
    "from utils.getch import getch\n",
    "import cv2\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logdir = 'data/fromphaedra/varying_x_scalar/linear_x0/'\n",
    "\n",
    "\n",
    "config = configs.load_config(logdir)\n",
    "env = gym.make(config['env'])\n",
    "tf.reset_default_graph()\n",
    "ml = ModelLearner(env, config)\n",
    "envmodel = ml.envmodel\n",
    "from utils.latest_checkpoint_unsafe import latest_checkpoint\n",
    "restore_path = latest_checkpoint(logdir)\n",
    "\n",
    "var_dict = {var.name[:-2]: var for var in tf.global_variables()}\n",
    "\n",
    "restoring_saver = tf.train.Saver(var_list=var_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-30 19:07:00,223] Restoring variables from checkpoint: data/fromphaedra/varying_x_scalar/linear_x0/model.ckpt-4993872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from data/fromphaedra/varying_x_scalar/linear_x0/model.ckpt-4993872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-30 19:07:00,225] Restoring parameters from data/fromphaedra/varying_x_scalar/linear_x0/model.ckpt-4993872\n",
      "[2017-07-30 19:07:15,508] Gameplay data gathered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3200, 11, 28, 28, 1), (3200, 11, 128), (3200, 11), (3200, 10), (3200, 10)]\n"
     ]
    }
   ],
   "source": [
    "num_evaluation_batches = 100\n",
    "max_validation_steps = 10\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if restore_path is not None:\n",
    "        logger.info(\"Restoring variables from checkpoint: {}\".format(restore_path))\n",
    "        restoring_saver.restore(sess, restore_path)\n",
    "    else:\n",
    "        logger.info(\"Initializing brand new network parameters.\")\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    ml.gather_gameplay_data(100)\n",
    "    transition_dataset = ml.create_transition_dataset(max_steps=max_validation_steps, variable_steps=False)\n",
    "    while transition_dataset[0].shape[0] < envmodel.test_batchsize*num_evaluation_batches:\n",
    "        ml.gather_gameplay_data(100)\n",
    "        transition_dataset = ml.create_transition_dataset(max_steps=max_validation_steps, variable_steps=False)\n",
    "    logger.info(\"Gameplay data gathered.\")\n",
    "    iterb = iterbatches(transition_dataset, batch_size=envmodel.test_batchsize)\n",
    "    latent_size = config['latent_size']\n",
    "    \n",
    "    states_full = np.zeros([0] + list(transition_dataset[0].shape[1:]))\n",
    "    latents_full = np.zeros([0, max_validation_steps + 1, latent_size])\n",
    "    labels_full = np.zeros([0, max_validation_steps + 1, 1])\n",
    "    truegv_full = np.zeros([0, max_validation_steps])\n",
    "    goalvalues_full = np.zeros([0, max_validation_steps])\n",
    "    for _ in range(num_evaluation_batches):\n",
    "        batch = next(iterb)\n",
    "        states, actions, _, truegoalvalues, goalstates, _, truelabels = batch\n",
    "        initial_states = states[:, 0]\n",
    "        initial_latents = envmodel.encode(initial_states)\n",
    "        _, future_latents = envmodel.stepforward(latent_state=initial_latents, actions=actions)\n",
    "        \n",
    "        # TODO: fix the below code (partially adapted from agents.py) to output goal predictions\n",
    "        goallatents = envmodel.encode(goalstates)\n",
    "        goallatents_flattened = np.tile(np.expand_dims(goallatents, axis=1),\n",
    "                                       [1, max_validation_steps, 1]).reshape([-1, latent_size])\n",
    "        flattened_latents = future_latents.reshape([-1, latent_size])\n",
    "        b = envmodel.test_batchsize\n",
    "        n_values = flattened_latents.shape[0]\n",
    "        goalvalues = []\n",
    "        for i in range(n_values//b + 1):\n",
    "            lower = i*b\n",
    "            upper = min((i+1)*b, n_values)\n",
    "            latents_chunk = flattened_latents[lower:upper]\n",
    "            goalstates_chunk = goallatents_flattened[lower:upper]\n",
    "            goalvalues_chunk = envmodel.checkgoal(latents_chunk, goalstates_chunk)\n",
    "            goalvalues.append(goalvalues_chunk)\n",
    "        goalvalues = np.concatenate(goalvalues, axis=0).reshape([b, max_validation_steps])\n",
    "\n",
    "        initial_latents = np.expand_dims(initial_latents, axis=1)\n",
    "        latents = np.concatenate([initial_latents, future_latents], axis=1)\n",
    "        states_full = np.concatenate([states_full, states], axis=0)\n",
    "        latents_full = np.concatenate([latents_full, latents], axis=0)\n",
    "        labels_full = np.concatenate([labels_full, truelabels], axis=0)\n",
    "        truegv_full = np.concatenate([truegv_full, truegoalvalues], axis=0)\n",
    "        goalvalues_full = np.concatenate([goalvalues_full, goalvalues], axis=0)\n",
    "\n",
    "labels_full = np.squeeze(labels_full, axis=-1)\n",
    "print([a.shape for a in [states_full, latents_full, labels_full, truegv_full, goalvalues_full]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: V score - 0.874744047626659, goal logloss - nan\n",
      "Step 1: V score - 0.6102813838595398, goal logloss - 0.0028595939096832824\n",
      "Step 2: V score - 0.5060910091403945, goal logloss - 0.00018927027911484726\n",
      "Step 3: V score - 0.47049308133867684, goal logloss - 0.0041822984053846955\n",
      "Step 4: V score - 0.41485322946089365, goal logloss - 0.0015843379948832852\n",
      "Step 5: V score - 0.47119871898678417, goal logloss - 0.0020196079486787216\n",
      "Step 6: V score - 0.4491585664434523, goal logloss - 0.0007438485618568385\n",
      "Step 7: V score - 0.49279644260531213, goal logloss - 0.000206371428040551\n",
      "Step 8: V score - 0.48577763933199264, goal logloss - 0.0017225612396981815\n",
      "Step 9: V score - 0.5156394030200999, goal logloss - 0.004817780503407745\n",
      "Step 10: V score - 0.5210340412096572, goal logloss - 0.010571734159334528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import log_loss, normalized_mutual_info_score as nmi_score\n",
    "kmeans_algorithm = KMeans(n_clusters=10, n_init=100)\n",
    "\n",
    "clustering_scores = []\n",
    "goal_scores = []\n",
    "goal_score = float('nan')\n",
    "for i in range(max_validation_steps + 1):\n",
    "    labels = labels_full[:, i]\n",
    "    latents = latents_full[:, i]\n",
    "    guessed_labels = kmeans_algorithm.fit_predict(latents)\n",
    "    clustering_score = nmi_score(labels, guessed_labels)\n",
    "    clustering_scores.append(clustering_score)\n",
    "    if i > 0:\n",
    "        true_goalvalues = truegv_full[:, i-1].astype(bool)\n",
    "        goalvalues = goalvalues_full[:, i-1]\n",
    "        goal_score = log_loss(true_goalvalues, goalvalues, labels=[0, 1])\n",
    "        goal_scores.append(goal_score)\n",
    "    print(\"Step {}: V score - {}, goal logloss - {}\".format(i, clustering_score, goal_score))\n",
    "clustering_scores = np.asarray(clustering_scores)\n",
    "goal_scores = np.asarray(goal_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
